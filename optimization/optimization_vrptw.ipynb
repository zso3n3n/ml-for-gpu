{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "489793aa",
   "metadata": {},
   "source": [
    "> Reminder: Use the ```cuopt-or``` kernel to run this notebook  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# GPU Acceleration Demo: VRPTW Optimization CPU vs GPU\n",
    "\n",
    "This notebook demonstrates GPU acceleration for Vehicle Routing Problem with Time Windows (VRPTW) using OR-Tools (CPU) vs cuOpt (GPU) on Gehring & Homberger RC2 dataset.\n",
    "\n",
    "**Objectives:**\n",
    "- Compare CPU vs GPU performance on VRPTW optimization\n",
    "- Measure solve-time speedups\n",
    "- Verify solution feasibility and quality\n",
    "- Demonstrate minimal migration effort (‚â§5 lines changed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "from ortools.constraint_solver import pywrapcp, routing_enums_pb2\n",
    "\n",
    "from cuopt.routing import DataModel, Solve, SolverSettings\n",
    "import cudf\n",
    "import cupy as cp\n",
    "\n",
    "# Add utils to path\n",
    "from utils.homberger_to_parquet import parse_homberger_file\n",
    "from utils.timing import set_cpu_threads, run_timed\n",
    "\n",
    "# Set reproducible seed\n",
    "np.random.seed(123)\n",
    "\n",
    "# Configure CPU threads for fair comparison\n",
    "set_cpu_threads(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Get and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SAMPLE = False  # Set to False for full dataset (1000 customers)\n",
    "extract_dir = \"data/homberger\"\n",
    "\n",
    "# Define data paths\n",
    "if USE_SAMPLE:\n",
    "    zip_file = \"data/homberger_200_customer_instances.zip\"\n",
    "    instance_pattern = r\"c2.*\\.txt\"  # C2 series, 200 customers\n",
    "    print(\"Using SAMPLE dataset (C2 series - 200 customers)\")\n",
    "else:\n",
    "    zip_file = \"data/homberger_1000_customer_instances.zip\"\n",
    "    instance_pattern = r\"rc2.*\\.txt\"  # RC2 series, 1000 customers\n",
    "    print(\"Using FULL dataset (RC2 series - 1000 customers)\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "def extract_and_parse_homberger():\n",
    "    \"\"\"Extract and parse Homberger VRPTW instance from ZIP file.\"\"\"\n",
    "    if not os.path.exists(zip_file):\n",
    "        raise FileNotFoundError(f\"Data file not found: {zip_file}\")\n",
    "\n",
    "    print(f\"üìÅ Extracting from: {os.path.basename(zip_file)}\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        # Match files by pattern, regardless of extension\n",
    "        if USE_SAMPLE:\n",
    "            pattern = \"C2_*\"\n",
    "        else:\n",
    "            pattern = \"RC2_*\"\n",
    "        matching_files = [f for f in zip_ref.namelist() if fnmatch.fnmatch(os.path.basename(f), pattern)]\n",
    "\n",
    "        if not matching_files:\n",
    "            # Fallback: use any file\n",
    "            matching_files = zip_ref.namelist()\n",
    "\n",
    "        instance_file = matching_files[0]\n",
    "        print(f\"üìã Using instance: {os.path.basename(instance_file)}\")\n",
    "\n",
    "        # Extract to temporary location\n",
    "        temp_path = os.path.join(extract_dir, \"temp_instance.txt\")\n",
    "        with zip_ref.open(instance_file) as source:\n",
    "            with open(temp_path, 'wb') as target:\n",
    "                target.write(source.read())\n",
    "\n",
    "        try:\n",
    "            customers_df, params = parse_homberger_file(temp_path)\n",
    "            return customers_df, params\n",
    "        finally:\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "\n",
    "# Extract and parse the data\n",
    "customers_df, vrptw_params = extract_and_parse_homberger()\n",
    "\n",
    "print(f\"\\nüìä VRPTW Instance: {vrptw_params['instance']}\")\n",
    "print(f\"Customers: {len(customers_df)}\")\n",
    "print(f\"Vehicles: {vrptw_params['K']}\")\n",
    "print(f\"Capacity: {vrptw_params['Q']}\")\n",
    "print(f\"Depot: ({vrptw_params['depot']['x']}, {vrptw_params['depot']['y']})\")\n",
    "print(f\"\\n‚úÖ Data loaded successfully\")\n",
    "print(f\"Customer data schema:\")\n",
    "print(customers_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vrptw_data(customers_df, params):\n",
    "    \"\"\"Convert DataFrame to optimization-ready format\"\"\"\n",
    "    \n",
    "    # Add depot as customer 0\n",
    "    depot = params['depot']\n",
    "    depot_row = pd.DataFrame({\n",
    "        'customer_id': [0],\n",
    "        'x': [depot['x']],\n",
    "        'y': [depot['y']],\n",
    "        'demand': [0],\n",
    "        'tw_start': [depot['tw_start']],\n",
    "        'tw_end': [depot['tw_end']],\n",
    "        'service_time': [depot['service_time']]\n",
    "    })\n",
    "    \n",
    "    # Combine depot and customers\n",
    "    all_locations = pd.concat([depot_row, customers_df], ignore_index=True)\n",
    "    all_locations = all_locations.sort_values('customer_id').reset_index(drop=True)\n",
    "    \n",
    "    # Calculate distance matrix (Euclidean)\n",
    "    n_locations = len(all_locations)\n",
    "    distance_matrix = np.zeros((n_locations, n_locations))\n",
    "    \n",
    "    for i in range(n_locations):\n",
    "        for j in range(n_locations):\n",
    "            if i != j:\n",
    "                dx = all_locations.iloc[i]['x'] - all_locations.iloc[j]['x']\n",
    "                dy = all_locations.iloc[i]['y'] - all_locations.iloc[j]['y']\n",
    "                distance_matrix[i][j] = int(np.sqrt(dx*dx + dy*dy))\n",
    "    \n",
    "    # Convert to lists for OR-Tools\n",
    "    data = {\n",
    "        'distance_matrix': distance_matrix.astype(int).tolist(),\n",
    "        'demands': all_locations['demand'].tolist(),\n",
    "        'time_windows': list(zip(all_locations['tw_start'], all_locations['tw_end'])),\n",
    "        'service_times': all_locations['service_time'].tolist(),\n",
    "        'num_vehicles': params['K'],\n",
    "        'vehicle_capacity': params['Q'],\n",
    "        'depot': 0\n",
    "    }\n",
    "    \n",
    "    return data, all_locations\n",
    "\n",
    "vrptw_data, locations_df = prepare_vrptw_data(customers_df, vrptw_params)\n",
    "\n",
    "print(f\"‚úÖ VRPTW data prepared:\")\n",
    "print(f\"Locations: {len(vrptw_data['distance_matrix']) - 1}\")\n",
    "print(f\"Vehicles: {vrptw_data['num_vehicles']}\")\n",
    "print(f\"Max distance: {np.max(vrptw_data['distance_matrix'])}\")\n",
    "print(f\"Total demand: {sum(vrptw_data['demands'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # Number of vehicles to use for both CPU and GPU\n",
    "    'num_vehicles': vrptw_data['num_vehicles'], #Note: Sample CPU solve requires 7 vehicles\n",
    "\n",
    "    # Relax time windows by this percent on each side (0 = no relax).\n",
    "    # Example: 20 means start -= 20% of (end-start), end += 20% of (end-start)\n",
    "    'tw_relax_pct': 0.0,\n",
    "\n",
    "    # Apply depot time window at vehicle start/end.\n",
    "    # Keep False by default to match GPU if its API doesn‚Äôt enforce depot TW.\n",
    "    'enforce_depot_tw': True,\n",
    "\n",
    "    # OR Early Stopping Params\n",
    "    'stall_secs': 60,\n",
    "    'rel_eps': 0.001,\n",
    "    'abs_eps': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## CPU Optimization - OR-Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60998fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopOnStall:\n",
    "    \"\"\"\n",
    "    Stop the Routing search when the incumbent hasn't improved by at least\n",
    "    `rel_eps` for `stall_secs` seconds (wall clock) since the last improvement.\n",
    "    \"\"\"\n",
    "    def __init__(self, routing_model: pywrapcp.RoutingModel,\n",
    "                 stall_secs: float = 30.0,\n",
    "                 rel_eps: float = 0.001,\n",
    "                 abs_eps: float = 0):\n",
    "        self._routing = routing_model\n",
    "        self._stall_secs = float(stall_secs)\n",
    "        self._rel_eps = float(rel_eps)\n",
    "        self._abs_eps = int(abs_eps)\n",
    "        self._best = None\n",
    "        self._last_impr = time.time()\n",
    "\n",
    "    def __call__(self):\n",
    "        curr = int(self._routing.CostVar().Value())\n",
    "        if self._best is None:\n",
    "            self._best = curr\n",
    "            self._last_impr = time.time()\n",
    "            return\n",
    "\n",
    "        rel_ok = curr <= self._best - max(int(self._best * self._rel_eps), 0)\n",
    "        abs_ok = curr <= self._best - self._abs_eps\n",
    "        if rel_ok or abs_ok:\n",
    "            self._best = curr\n",
    "            self._last_impr = time.time()\n",
    "        else:\n",
    "            if time.time() - self._last_impr >= self._stall_secs:\n",
    "                # cooperative stop (ends current search cleanly)\n",
    "                self._routing.solver().FinishCurrentSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CPU BUILD ---\n",
    "def build_cpu_model(data,\n",
    "                    stall_secs=CONFIG['stall_secs'],\n",
    "                    rel_eps=CONFIG['rel_eps'],\n",
    "                    abs_eps=CONFIG['abs_eps']):\n",
    "    num_vehicles = CONFIG['num_vehicles']\n",
    "    manager = pywrapcp.RoutingIndexManager(\n",
    "        len(data['distance_matrix']),\n",
    "        num_vehicles,\n",
    "        data['depot']\n",
    "    )\n",
    "    routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "    def distance_callback(from_index, to_index):\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        return int(data['distance_matrix'][from_node][to_node])\n",
    "    transit_cb = routing.RegisterTransitCallback(distance_callback)\n",
    "    routing.SetArcCostEvaluatorOfAllVehicles(transit_cb)\n",
    "\n",
    "    def demand_callback(from_index):\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        return int(data['demands'][from_node])\n",
    "    demand_cb = routing.RegisterUnaryTransitCallback(demand_callback)\n",
    "    routing.AddDimensionWithVehicleCapacity(\n",
    "        demand_cb, 0,\n",
    "        [data['vehicle_capacity']] * num_vehicles,\n",
    "        True, 'Capacity'\n",
    "    )\n",
    "\n",
    "    if data['service_times'][data['depot']] != 0:\n",
    "        data['service_times'][data['depot']] = 0  # parity with GPU\n",
    "    \n",
    "    def time_callback(from_index, to_index):\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        travel_time = data['distance_matrix'][from_node][to_node]\n",
    "        # Departure-based service: add service of the node you are leaving (skip depot)\n",
    "        service_time = 0 if from_node == data['depot'] else data['service_times'][from_node]\n",
    "        return int(service_time + travel_time)\n",
    "\n",
    "    time_cb = routing.RegisterTransitCallback(time_callback)\n",
    "\n",
    "    \n",
    "\n",
    "    max_tw_end = max(tw[1] for tw in data['time_windows'])\n",
    "    horizon = int(max_tw_end * 2)\n",
    "    max_width = max(b - a for (a,b) in vrptw_data['time_windows'])\n",
    "    slack_max = int(max_width)\n",
    "    routing.AddDimension(time_cb, slack_max, horizon, False, 'Time')\n",
    "    time_dimension = routing.GetDimensionOrDie('Time')\n",
    "\n",
    "    relax_frac = float(CONFIG.get('tw_relax_pct', 0)) / 100.0\n",
    "    def relaxed_tw(tw):\n",
    "        start, end = int(tw[0]), int(tw[1])\n",
    "        if relax_frac <= 0 or end <= start:\n",
    "            return start, end\n",
    "        width = end - start\n",
    "        return max(0, int(start - relax_frac * width)), int(end + relax_frac * width)\n",
    "\n",
    "    depot_idx = data['depot']\n",
    "    depot_tw = data['time_windows'][depot_idx]\n",
    "    for location_idx, tw in enumerate(data['time_windows']):\n",
    "        if location_idx == depot_idx:\n",
    "            continue\n",
    "        index = manager.NodeToIndex(location_idx)\n",
    "        if index != -1:\n",
    "            lo, hi = relaxed_tw(tw)\n",
    "            time_dimension.CumulVar(index).SetRange(lo, hi)\n",
    "\n",
    "    if CONFIG.get('enforce_depot_tw', False):\n",
    "        for v in range(num_vehicles):\n",
    "            s = routing.Start(v); e = routing.End(v)\n",
    "            time_dimension.CumulVar(s).SetRange(int(depot_tw[0]), int(depot_tw[1]))\n",
    "            time_dimension.CumulVar(e).SetRange(int(depot_tw[0]), int(depot_tw[1]))\n",
    "\n",
    "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "    search_parameters.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.PARALLEL_CHEAPEST_INSERTION \n",
    "    search_parameters.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH\n",
    "    search_parameters.log_search = False\n",
    "\n",
    "    stall_cb = EarlyStopOnStall(routing,\n",
    "                                stall_secs=stall_secs,\n",
    "                                rel_eps=rel_eps,\n",
    "                                abs_eps=abs_eps)\n",
    "    routing.AddAtSolutionCallback(stall_cb)\n",
    "    return routing, manager, search_parameters\n",
    "\n",
    "# --- CPU SOLVE ---\n",
    "def solve_cpu(built):\n",
    "    routing, manager, search_parameters = built\n",
    "    solution = routing.SolveWithParameters(search_parameters)\n",
    "    return solution, routing, manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## GPU Optimization - cuOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GPU Warmup ---\n",
    "def gpu_warmup():\n",
    "    \"\"\"Warm up GPU with a small VRPTW problem to avoid cold start overhead.\"\"\"\n",
    "    dm = DataModel(6, 2, 5)\n",
    "    ss = SolverSettings()\n",
    "    ss.set_time_limit(1)\n",
    "    dm.add_cost_matrix(cudf.DataFrame(cp.eye(6, dtype=cp.int32)))\n",
    "    \n",
    "    dm.add_capacity_dimension(\n",
    "        \"demand\",\n",
    "        cudf.Series(cp.ones(5, dtype=cp.int32)),\n",
    "        cudf.Series(cp.full(2, 10, dtype=cp.int32))\n",
    "    )\n",
    "    dm.set_order_locations(cudf.Series(cp.arange(1, 6, dtype=cp.int32)))\n",
    "\n",
    "    _ = Solve(dm, ss)\n",
    "    return\n",
    "\n",
    "# --- GPU BUILD ---\n",
    "def build_gpu_model(data):\n",
    "    n_locations = len(data['distance_matrix'])\n",
    "    n_orders = n_locations - 1\n",
    "    n_vehicles = CONFIG['num_vehicles']\n",
    "    data_model = DataModel(n_locations, n_vehicles, n_orders)\n",
    "\n",
    "    distance_matrix_cudf = cudf.DataFrame(data['distance_matrix'], dtype='int32')\n",
    "    data_model.add_cost_matrix(distance_matrix_cudf)\n",
    "\n",
    "    demands_cudf_orders = cudf.Series(data['demands'][1:], dtype='int32')\n",
    "    vehicle_capacities_cudf = cudf.Series([data['vehicle_capacity']] * n_vehicles, dtype='int32')\n",
    "    data_model.add_capacity_dimension(\"demand\", demands_cudf_orders, vehicle_capacities_cudf)\n",
    "\n",
    "    order_indices = cudf.Series(cp.arange(1, n_locations, dtype=cp.int32))\n",
    "    data_model.set_order_locations(order_indices)\n",
    "\n",
    "    relax_frac = float(CONFIG.get('tw_relax_pct', 0)) / 100.0\n",
    "    def relaxed_tw(tw):\n",
    "        start, end = int(tw[0]), int(tw[1])\n",
    "        if relax_frac <= 0 or end <= start:\n",
    "            return start, end\n",
    "        width = end - start\n",
    "        return max(0, int(start - relax_frac * width)), int(end + relax_frac * width)\n",
    "\n",
    "    e_list, l_list = [], []\n",
    "    for tw in data['time_windows'][1:]:\n",
    "        lo, hi = relaxed_tw(tw)\n",
    "        e_list.append(int(lo)); l_list.append(int(hi))\n",
    "    data_model.set_order_time_windows(\n",
    "        cudf.Series(e_list, dtype='int32'),\n",
    "        cudf.Series(l_list, dtype='int32')\n",
    "    )\n",
    "\n",
    "    service_times = cudf.Series([int(st) for st in data['service_times'][1:]], dtype='int32')\n",
    "    data_model.set_order_service_times(service_times)\n",
    "\n",
    "    depot_idx = int(data['depot'])\n",
    "    starts = cudf.Series([depot_idx] * n_vehicles, dtype='int32')\n",
    "    ends = cudf.Series([depot_idx] * n_vehicles, dtype='int32')\n",
    "    data_model.set_vehicle_locations(starts, ends)\n",
    "\n",
    "    if CONFIG.get('enforce_depot_tw', False) and hasattr(data_model, 'set_vehicle_time_windows'):\n",
    "        depot_tw = data['time_windows'][depot_idx]\n",
    "        st, et = int(depot_tw[0]), int(depot_tw[1])\n",
    "        data_model.set_vehicle_time_windows(\n",
    "            cudf.Series([st]*n_vehicles, dtype='int32'),\n",
    "            cudf.Series([et]*n_vehicles, dtype='int32')\n",
    "        )\n",
    "\n",
    "    solver_settings = SolverSettings()\n",
    "    return data_model, solver_settings\n",
    "\n",
    "# --- GPU SOLVE ---\n",
    "def solve_gpu(built):\n",
    "    data_model, solver_settings = built\n",
    "    return Solve(data_model, solver_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3779595",
   "metadata": {},
   "source": [
    "### Extract Solve Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cpu_metrics(solution_obj, routing, manager, data):\n",
    "    if not solution_obj:\n",
    "        return {'feasible': False}\n",
    "    num_vehicles = CONFIG['num_vehicles']\n",
    "    total_distance = 0\n",
    "    total_served = 0\n",
    "    total_utilization = 0.0\n",
    "    used_vehicles = 0\n",
    "\n",
    "    for vehicle_id in range(num_vehicles):\n",
    "        index = routing.Start(vehicle_id)\n",
    "        route_distance = 0\n",
    "        route_demand = 0\n",
    "        visit_count = 0\n",
    "        while not routing.IsEnd(index):\n",
    "            node_index = manager.IndexToNode(index)\n",
    "            previous_index = index\n",
    "            index = solution_obj.Value(routing.NextVar(index))\n",
    "            route_distance += routing.GetArcCostForVehicle(previous_index, index, vehicle_id)\n",
    "            if node_index != data['depot']:\n",
    "                route_demand += data['demands'][node_index]\n",
    "                visit_count += 1\n",
    "        if visit_count > 0:\n",
    "            used_vehicles += 1\n",
    "            total_distance += route_distance\n",
    "            total_served += visit_count\n",
    "            if data['vehicle_capacity'] > 0:\n",
    "                total_utilization += route_demand / data['vehicle_capacity']\n",
    "\n",
    "    avg_utilization = total_utilization / used_vehicles if used_vehicles else 0.0\n",
    "    return {\n",
    "        'feasible': True,\n",
    "        'objective': int(total_distance),\n",
    "        'num_routes': used_vehicles,\n",
    "        'customers_served': total_served,\n",
    "        'avg_utilization': avg_utilization\n",
    "    }\n",
    "\n",
    "def extract_gpu_metrics(routing_solution, data):\n",
    "    if routing_solution is None:\n",
    "        return {'feasible': False}\n",
    "    # Objective\n",
    "    if hasattr(routing_solution, 'get_total_objective'):\n",
    "        total_cost = float(routing_solution.get_total_objective())\n",
    "    elif hasattr(routing_solution, 'total_objective_value'):\n",
    "        total_cost = float(routing_solution.total_objective_value)\n",
    "    else:\n",
    "        total_cost = 0.0\n",
    "\n",
    "    route_df = routing_solution.get_route()  # cuDF\n",
    "    depot_idx = data['depot']\n",
    "    df_visits = route_df[route_df['location'] != depot_idx]\n",
    "\n",
    "    demands_series = cudf.Series(data['demands'], dtype='int32')\n",
    "    df_visits = df_visits.assign(demand=demands_series.take(df_visits['location']))\n",
    "\n",
    "    per_truck = df_visits.groupby('truck_id')['demand'].sum()\n",
    "    used_vehicles = int(len(per_truck))\n",
    "    customers_served = int(len(df_visits))\n",
    "\n",
    "    cap = max(1, int(data['vehicle_capacity']))\n",
    "    if used_vehicles == 0:\n",
    "        avg_utilization = 0.0\n",
    "    else:\n",
    "        avg_utilization = float((per_truck.astype('float32') / float(cap)).fillna(0).mean())\n",
    "\n",
    "    return {\n",
    "        'feasible': True,\n",
    "        'objective': int(total_cost) if total_cost else 0,\n",
    "        'num_routes': used_vehicles,\n",
    "        'customers_served': customers_served,\n",
    "        'avg_utilization': avg_utilization\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3c746",
   "metadata": {},
   "source": [
    "## Run Solves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b197a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. CPU Phase (Build -> Solve -> Metrics) ---\n",
    "print(\"üß† CPU Phase starting...\")\n",
    "(cpu_built, cpu_build_time) = run_timed(\n",
    "    \"CPU Build\",\n",
    "    lambda: build_cpu_model(vrptw_data),\n",
    "    use_gpu=False\n",
    ")\n",
    "(cpu_solution_tuple, cpu_search_time) = run_timed(\n",
    "    \"CPU Solve\",\n",
    "    lambda: solve_cpu(cpu_built),\n",
    "    use_gpu=False\n",
    ")\n",
    "cpu_solution_obj, cpu_routing, cpu_manager = cpu_solution_tuple\n",
    "(cpu_metrics, cpu_metrics_time) = run_timed(\n",
    "    \"CPU Metrics\",\n",
    "    lambda: extract_cpu_metrics(cpu_solution_obj, cpu_routing, cpu_manager, vrptw_data),\n",
    "    use_gpu=False\n",
    ")\n",
    "print(\"CPU metrics:\", cpu_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. GPU Phase (Build -> Solve -> Metrics) ---\n",
    "\n",
    "print(\"üöÄ GPU Phase starting...\")\n",
    "gpu_warmup_result, gpu_warmup_time = run_timed(\n",
    "    \"GPU Warmup\",\n",
    "    gpu_warmup,\n",
    "    use_gpu=True\n",
    ")\n",
    "(gpu_built, gpu_build_time) = run_timed(\n",
    "    \"GPU Build\",\n",
    "    lambda: build_gpu_model(vrptw_data),\n",
    "    use_gpu=True\n",
    ")\n",
    "(gpu_solution_obj, gpu_search_time) = run_timed(\n",
    "    \"GPU Solve\",\n",
    "    lambda: solve_gpu(gpu_built),\n",
    "    use_gpu=True\n",
    ")\n",
    "(gpu_metrics, gpu_metrics_time) = run_timed(\n",
    "    \"GPU Metrics\",\n",
    "    lambda: extract_gpu_metrics(gpu_solution_obj, vrptw_data),\n",
    "    use_gpu=True\n",
    ")\n",
    "print(\"GPU metrics:\", gpu_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Performance Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da430b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Feasibility Validation (uses previously defined validators or add minimal ones) ---\n",
    "def validate_cpu(solution_obj, routing, manager, data):\n",
    "    if not solution_obj:\n",
    "        return {'side':'CPU','feasible':False,'customers_served':0}\n",
    "    depot = data['depot']\n",
    "    served = set()\n",
    "    capacity_ok = True\n",
    "    for v in range(CONFIG['num_vehicles']):\n",
    "        idx = routing.Start(v)\n",
    "        load = 0\n",
    "        while not routing.IsEnd(idx):\n",
    "            node = manager.IndexToNode(idx)\n",
    "            nxt = solution_obj.Value(routing.NextVar(idx))\n",
    "            if node != depot:\n",
    "                served.add(node)\n",
    "                load += data['demands'][node]\n",
    "            idx = nxt\n",
    "        if load > data['vehicle_capacity']:\n",
    "            capacity_ok = False\n",
    "    n_customers = len(data['demands']) - 1\n",
    "    return {\n",
    "        'side':'CPU',\n",
    "        'feasible': capacity_ok and len(served)==n_customers,\n",
    "        'customers_served': len(served),\n",
    "        'all_customers': n_customers,\n",
    "        'capacity_ok': capacity_ok\n",
    "    }\n",
    "\n",
    "def validate_gpu(solution_obj, data):\n",
    "    if solution_obj is None:\n",
    "        return {'side':'GPU','feasible':False,'customers_served':0}\n",
    "    depot = data['depot']\n",
    "    route_df = solution_obj.get_route()\n",
    "    visits = route_df[route_df['location'] != depot]\n",
    "    served = set(int(x) for x in visits['location'].to_pandas())\n",
    "    n_customers = len(data['demands']) - 1\n",
    "    demands_series = cudf.Series(data['demands'], dtype='int32')\n",
    "    cap = data['vehicle_capacity']\n",
    "    cap_ok = True\n",
    "    for _, grp in visits.groupby('truck_id'):\n",
    "        load = int(demands_series.take(grp['location']).sum())\n",
    "        if load > cap:\n",
    "            cap_ok = False\n",
    "            break\n",
    "    return {\n",
    "        'side':'GPU',\n",
    "        'feasible': cap_ok and len(served)==n_customers,\n",
    "        'customers_served': len(served),\n",
    "        'all_customers': n_customers,\n",
    "        'capacity_ok': cap_ok\n",
    "    }\n",
    "\n",
    "(validation_results, validation_time) = run_timed(\n",
    "    \"Feasibility Validation\",\n",
    "    lambda: [validate_cpu(cpu_solution_obj, cpu_routing, cpu_manager, vrptw_data),\n",
    "             validate_gpu(gpu_solution_obj, vrptw_data)],\n",
    "    use_gpu=True\n",
    ")\n",
    "validation_df = pd.DataFrame(validation_results)\n",
    "print(validation_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Performance Comparison & Analysis ---\n",
    "cpu_feasible = cpu_metrics.get('feasible', False)\n",
    "gpu_feasible = gpu_metrics.get('feasible', False)\n",
    "\n",
    "# Calculate speedup ratios\n",
    "if gpu_search_time > 0:\n",
    "    pure_search_speedup = cpu_search_time / gpu_search_time\n",
    "else:\n",
    "    pure_search_speedup = float('inf')\n",
    "\n",
    "if gpu_build_time > 0:\n",
    "    build_speed_ratio = cpu_build_time / gpu_build_time\n",
    "else:\n",
    "    build_speed_ratio = float('inf')\n",
    "\n",
    "if gpu_metrics_time > 0:\n",
    "    metrics_speed_ratio = cpu_metrics_time / gpu_metrics_time\n",
    "else:\n",
    "    metrics_speed_ratio = float('inf')\n",
    "\n",
    "# Calculate objective improvement\n",
    "if (cpu_feasible and gpu_feasible and cpu_metrics.get('objective',0) > 0):\n",
    "    objective_improvement = (cpu_metrics['objective'] - gpu_metrics['objective']) / cpu_metrics['objective'] * 100\n",
    "else:\n",
    "    objective_improvement = 0.0\n",
    "\n",
    "# Calculate total times\n",
    "cpu_total_time = cpu_build_time + cpu_search_time + cpu_metrics_time\n",
    "gpu_total_time = gpu_warmup_time + gpu_build_time + gpu_search_time + gpu_metrics_time\n",
    "\n",
    "if gpu_total_time > 0:\n",
    "    total_speedup = cpu_total_time / gpu_total_time\n",
    "else:\n",
    "    total_speedup = float('inf')\n",
    "\n",
    "comparison_rows = [\n",
    "    {'Metric':'Build Time (s)',\n",
    "     'CPU (OR-Tools)': f\"{cpu_build_time:.3f}\",\n",
    "     'GPU (cuOpt)': f\"{gpu_build_time:.3f}\",\n",
    "     'Speedup/Improvement': f\"{build_speed_ratio:.2f}x\"},\n",
    "    {'Metric':'Solve/Search Time (s)',\n",
    "     'CPU (OR-Tools)': f\"{cpu_search_time:.3f}\",\n",
    "     'GPU (cuOpt)': f\"{gpu_search_time:.3f}\",\n",
    "     'Speedup/Improvement': f\"{pure_search_speedup:.2f}x\"},\n",
    "    {'Metric':'GPU Warmup Time (s)',\n",
    "     'CPU (OR-Tools)': 'N/A',\n",
    "     'GPU (cuOpt)': f\"{gpu_warmup_time:.3f}\",\n",
    "     'Speedup/Improvement': ''},\n",
    "    {'Metric':'Metrics Time (s)',\n",
    "     'CPU (OR-Tools)': f\"{cpu_metrics_time:.3f}\",\n",
    "     'GPU (cuOpt)': f\"{gpu_metrics_time:.3f}\",\n",
    "     'Speedup/Improvement': f\"{metrics_speed_ratio:.2f}x\"},\n",
    "    {'Metric':'Total Time (s)',\n",
    "     'CPU (OR-Tools)': f\"{cpu_total_time:.3f}\",\n",
    "     'GPU (cuOpt)': f\"{gpu_total_time:.3f}\",\n",
    "     'Speedup/Improvement': f\"{total_speedup:.2f}x\"},\n",
    "    {'Metric':'Vehicle Distance',\n",
    "     'CPU (OR-Tools)': f\"{cpu_metrics.get('objective','-')}\",\n",
    "     'GPU (cuOpt)': f\"{gpu_metrics.get('objective','-')}\",\n",
    "     'Speedup/Improvement': f\"{objective_improvement:+.1f}%\" if abs(objective_improvement) > 0.1 else \"Same\"},\n",
    "    {'Metric':'Routes Used',\n",
    "     'CPU (OR-Tools)': f\"{cpu_metrics.get('num_routes','-')}\",\n",
    "     'GPU (cuOpt)': f\"{gpu_metrics.get('num_routes','-')}\",\n",
    "     'Speedup/Improvement': (\n",
    "         f\"{cpu_metrics['num_routes']-gpu_metrics['num_routes']:+d}\"\n",
    "         if cpu_metrics.get('num_routes') is not None and gpu_metrics.get('num_routes') is not None and\n",
    "            cpu_metrics['num_routes'] != gpu_metrics['num_routes'] else 'Same')},\n",
    "    {'Metric':'Customers Served',\n",
    "     'CPU (OR-Tools)': f\"{cpu_metrics.get('customers_served','-')}/{len(customers_df)}\",\n",
    "     'GPU (cuOpt)': f\"{gpu_metrics.get('customers_served','-')}/{len(customers_df)}\",\n",
    "     'Speedup/Improvement': 'Same' if cpu_metrics.get('customers_served') == gpu_metrics.get('customers_served') else 'Different'},\n",
    "    {'Metric':'Vehicle Utilization',\n",
    "     'CPU (OR-Tools)': f\"{cpu_metrics.get('avg_utilization',0):.2f}\",\n",
    "     'GPU (cuOpt)': f\"{gpu_metrics.get('avg_utilization',0):.2f}\",\n",
    "     'Speedup/Improvement': 'Same' if abs(cpu_metrics.get('avg_utilization',0) - gpu_metrics.get('avg_utilization',0)) < 0.01 else 'Different'}\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_rows)\n",
    "print(\"‚ö° VRPTW CPU vs GPU Performance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuopt-or",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
